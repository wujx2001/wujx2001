This site contains repositories that make efficient training and inference of deep neural networks, produced by members of the group at Nanjing University led by [Jianxin Wu](https://cs.nju.edu.cn/wujx).

Repositories include

* **[QwT (Quantization without Tears)](https://github.com/wujx2001/qwt.git)**

  * **Brief description:**
    QwT is a fast and accurate post-training quantization method that integrates seamlessly into your workflow by augmenting any PTQ model with lightweight linear compensation layers. These layers are computed in closed form on a small calibration set to recover information loss during INT-type quantization, delivering PTQ accuracy comparable.
  * **Developed by:**
    Minghao Fu, Hao Yu, Jie Shao, Junjie Zhou, Ke Zhu, Jianxin Wu
  


